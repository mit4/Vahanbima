{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd8743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89a9d522",
   "metadata": {},
   "source": [
    "<center> <img src=\"https://www.goodreturns.in/img/2016/01/insuranceauto-25-1453703850.jpg\" /> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34806777",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b49ca",
   "metadata": {},
   "source": [
    "# Problem Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff67e3",
   "metadata": {},
   "source": [
    "VahanBima is one of the leading insurance companies in India. It provides motor vehicle insurances at best prices with 24/7 claim settlement.  It offers different types of policies for  both personal and commercial vehicles. It has established its brand across different regions in India. \n",
    "\n",
    "Around 90% of the businesses today use personalized services. The company wants to launch different personalized experience programs for customers of VahanBima. The personalized experience can be dedicated resources for claim settlement, different kinds of services at doorstep, etc. Inorder to do so, they would like to segment the customers into different tiers based on their customer lifetime value (CLTV).\n",
    "\n",
    "Inorder to do it, they would like to predict the customer lifetime value based on the activity and interaction of the customer with the platform. So, as a part of this challenge, your task at hand is to build a high performance and interpretable machine learning model to predict the CLTV based on the user and policy data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb7de2",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171bb38b",
   "metadata": {},
   "source": [
    "You are provided with the sample dataset of the company holding the information of customers and policy such as highest qualification of the user, total income earned by a customer in a year, employee status,  policy opted by the user, type of policy and so on and the target variable indicating the total customer lifetime value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d52bf1",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb5f93",
   "metadata": {},
   "source": [
    "You are provided with 3 files - train.csv, test.csv and sample_submission.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2211c8",
   "metadata": {},
   "source": [
    "### Training Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99831e3b",
   "metadata": {},
   "source": [
    "You are provided with around 90K records containing the attributes of the user and policy and the target variable cltv indicating the total customer lifetime value.\n",
    "\n",
    "|Variable       |Description                                                |\n",
    "| ------------- |:-------------                                            :| \n",
    "|id             |Unique identifier of a customer                            |\n",
    "|gender         |Gender of the customer                                     |\n",
    "|area           |Area of the customer                                       |\n",
    "|qualification  |Highest Qualification of the customer                      |\n",
    "|income         |Income earned in a year (in rupees)                        |\n",
    "|marital_status |Marital Status of the customer {0:Single, 1: Married}      |\n",
    "|vintage        |No. of years since the first policy date                   |\n",
    "|claim_amount   |Total Amount Claimed by the customer (in rupees)           |\n",
    "|num_policies   |Total no. of policies issued by the customer               |\n",
    "|policy         |Active policy of the customer                              |\n",
    "|type_of_policy |Type of active policy                                      |\n",
    "|cltv           |Customer life time value (Target Variable)                 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bebd6",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Numerical Python\n",
    "import numpy as np\n",
    "\n",
    "# For Panel Data Analysis\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# For Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# To Disable Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a756f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Data Model Development\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Machine Learning Model Evaluation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f064e8",
   "metadata": {},
   "source": [
    "# Importing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5635f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_BRCpofr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6511bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a85cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b134ed",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dbb648",
   "metadata": {},
   "source": [
    "- 89392 observations in data and no missing entries\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['income'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3bac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['qualification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vintage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11992db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_policies'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3b080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['policy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ddd8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['type_of_policy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ffbb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data.vintage)\n",
    "plt.axvline(data.vintage.mean(), color='r')\n",
    "plt.axvline(data.vintage.median(), color='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7683b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas_profiling import ProfileReport \n",
    "#profile = ProfileReport(df=data)\n",
    "#profile.to_file(output_file='Pre Profiling Report.html')\n",
    "#print('Accomplished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0359394c",
   "metadata": {},
   "source": [
    "### Observations\n",
    " \n",
    "- Total 89392 observations and 12 columns in data. **No Missing** values in data.\n",
    "- Of 12 columns **8 catagorical and 4 numerical columns**.\n",
    "- 56-44 Male-Female ratio customer.\n",
    "- **Majority(70%)** of customers are from **Urban** `area`.\n",
    "- **59%** customers are in **5L-10L Income** slab, then **23% in 2L-5L** slab.\n",
    "- **57%** customers are married.\n",
    "- **20%** customers have **claimed  nothing**.\n",
    "- **Claimed amount** column have **positive skewness** of 1. 95th percentile is 10078 and max value is 31894 suggesting **there are some outliers**.\n",
    "- **67.4%** customers have **more than 1 policy**.\n",
    "- **63.4%** customers have **A poicy** followed by **27.6** have **B policy**.\n",
    "- **Platnum policy type** have **maximum(53.5%)** distribution in data set. Other two types have equal distribution.\n",
    "- `CLTV` has **mean 97952** and **median 66396**\n",
    "    - kewness is **2.75** suggesting data is little bit skewed.\n",
    "    - he 95th percentile is 307265 and maximum value is 724068.\n",
    "- There is some **correlation** between\n",
    "    - Area and claim amount**.\n",
    "    - CLTV and No. of policies**.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(), annot=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53af918",
   "metadata": {},
   "source": [
    "##  relation between cltv and claim amount?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cec6900",
   "metadata": {},
   "source": [
    "## vintage , cltv and policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061bdb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dbfe5a",
   "metadata": {},
   "source": [
    "- **20%** customers had their **first policy 6 years ago.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat(data):    \n",
    "    p=[]\n",
    "    for i in range(len(data)):\n",
    "        if data.vintage[i] != 0:\n",
    "            a = data.claim_amount[i] / data.vintage[i]\n",
    "            p.append(a)\n",
    "        else:\n",
    "            p.append(0)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cefc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['claim_per_year'] = creat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019fab1c",
   "metadata": {},
   "source": [
    "<a id = Section7></a>\n",
    "## **7. Post Data Processing & Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935e4e4",
   "metadata": {},
   "source": [
    "<a id = Section701></a>\n",
    "### **7.1 Encoding Categorical Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de024ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variable of the Type column\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a41081",
   "metadata": {},
   "source": [
    "<a id = Section704></a>\n",
    "### **7.3 Data Splitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5e20a",
   "metadata": {},
   "source": [
    "- Now, we will **split** the dataset into **Train** and **Test** subsets.\n",
    "\n",
    "- We will use **80%** data for **training** and the remaining **20%** data for **testing** our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace08002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the feature matrix by removing the target variable\n",
    "X = data.drop(['cltv','id'], axis=1)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3726651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the target vector\n",
    "y = data['cltv']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9923eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MinMaxScaler()\n",
    "sc = s.fit_transform(X[['claim_amount','claim_per_year']])\n",
    "sc = pd.DataFrame(sc ,columns=['claim_amount','claim_per_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d5cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =X.drop(labels=['claim_amount','claim_per_year'], axis=1)\n",
    "X = pd.concat(objs=[X,sc], axis=1 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfdb8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scikit-learn's train_test_split function to split the dataset into train and test sets.\n",
    "# 80% of the data will be in the train set and 20% in the test set, as specified by test_size=0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c72571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shapes of the training and test sets.\n",
    "print('Training Data Shape:', X_train.shape, y_train.shape)\n",
    "print('Testing Data Shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d8ce3",
   "metadata": {},
   "source": [
    "<a id = Section8></a>\n",
    "## **8. Model Development & Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dca92f7",
   "metadata": {},
   "source": [
    "- In this section, we will be **building** our Machine Learning models and fitting them with the training data.\n",
    "\n",
    "- We will be building models using:\n",
    "\n",
    "  - **All** the **features** of the training set.\n",
    "\n",
    "  - The most **important features** of the training set, according to the Random Forest algorithm.\n",
    "\n",
    "- We will use **K-fold Cross Validation** to validate our models and select the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29448e54",
   "metadata": {},
   "source": [
    "- We are creating a **helper function** `display_scores` that will help us in **displaying** our *K-fold cross validation* **scores**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to display the scores along with the mean and standard deviation of scores.\n",
    "def display_scores(scores):\n",
    "    scores_rmse = np.sqrt(-scores)\n",
    "    print('Scores:', scores_rmse)\n",
    "    print('Mean:', scores_rmse.mean())\n",
    "    print('Standard Deviation:', scores_rmse.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529fc83",
   "metadata": {},
   "source": [
    "<a id = Section801></a>\n",
    "### **8.1 Baseline Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864d51c",
   "metadata": {},
   "source": [
    "- In the baseline models, we will be using **all** the **features** of the dataset in our models.\n",
    "\n",
    "- We will be performing **5-fold** cross-validation to **validate** our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b431fc8b",
   "metadata": {},
   "source": [
    "<a id = Section80101></a>\n",
    "#### **8.1.1 Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing K-fold Cross-validation for 5 folds.\n",
    "scores = cross_val_score(estimator=base_lr, X=X_train, y=y_train, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae45b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the RMSE scores with display_score helper function.\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a9b59",
   "metadata": {},
   "source": [
    "<a id = Section80102></a>\n",
    "#### **8.1.2 Decision Tree Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dt = DecisionTreeRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d51630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing K-fold Cross-validation for 5 folds.\n",
    "scores = cross_val_score(estimator=base_dt, X=X_train, y=y_train, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the RMSE scores with display_score helper function.\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7a8f9",
   "metadata": {},
   "source": [
    "<a id = Section80103></a>\n",
    "#### **8.1.3 Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Random Forest model.\n",
    "base_rf = RandomForestRegressor(n_estimators=10, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d867906",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Performing K-fold Cross-validation for 5 folds.\n",
    "scores = cross_val_score(estimator=base_rf, X=X_train, y=y_train, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the RMSE scores with display_score helper function.\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca6389",
   "metadata": {},
   "source": [
    "#### **Checking Feature Importances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the baseline Random Forest model on the entire train set to obtain the feature importances of each feature. \n",
    "base_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b064aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the feature importances of various features.\n",
    "# Sorting the importances by descending order (lowest importance at the bottom).\n",
    "for score, name in sorted(zip(base_rf.feature_importances_, X_train.columns), reverse=True):\n",
    "    print('Feature importance of', name, ':', score*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93877259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Feature Importance of each feature.\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.bar(X_train.columns, base_rf.feature_importances_*100, color='green')\n",
    "plt.xlabel('Features', fontsize=14)\n",
    "plt.ylabel('Importance', fontsize=14)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Feature Importance of each Feature', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0accac6",
   "metadata": {},
   "source": [
    "<a id = Section802></a>\n",
    "### **8.2 Essential Feature Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b2b72",
   "metadata": {},
   "source": [
    "- In the essential feature models, we will be using only the **most important features** of the dataset in our models.\n",
    "\n",
    "- The features are selected on the basis of the **feature importance** obtained from the Random Forest model.\n",
    "\n",
    "- We will be performing **5-fold** cross-validation to **validate** our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e1c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_essential = X_train[['claim_amount', 'num_policies_More than 1', 'vintage', 'qualification_High School','qualification_High School', 'type_of_policy_Platinum', 'gender_Male', 'income_5L-10L','type_of_policy_Silver', 'income_More than 10L','claim_per_year' ]]\n",
    "X_train_essential.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c6ad6",
   "metadata": {},
   "source": [
    "<a id = Section80201></a>\n",
    "#### **8.2.1 Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ada8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a3a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing K-fold Cross-validation for 5 folds.\n",
    "scores = cross_val_score(estimator=essential_lr, X=X_train_essential, y=y_train, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d0adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the RMSE scores with display_score helper function.\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6587db1e",
   "metadata": {},
   "source": [
    "<a id = Section80202></a>\n",
    "#### **8.2.2 Decision Tree Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a165e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_dt = DecisionTreeRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f77219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing K-fold Cross-validation for 5 folds.\n",
    "scores = cross_val_score(estimator=essential_dt, X=X_train_essential, y=y_train, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the RMSE scores with display_score helper function.\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985fea6",
   "metadata": {},
   "source": [
    "<a id = Section80203></a>\n",
    "#### **8.2.3 Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Random Forest model.\n",
    "essential_rf = RandomForestRegressor(n_estimators=10, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf186311",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Performing K-fold Cross-validation for 5 folds.\n",
    "scores = cross_val_score(estimator=essential_rf, X=X_train_essential, y=y_train, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f8ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the RMSE scores with display_score helper function.\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94e9f1a",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- The mean **RMSE** score for the Essential Feature Random Forest Model is \n",
    "\n",
    "- Our model has improved even though we are using only a **subset** (i. e. 6 features) of the features from the entire dataset.\n",
    "\n",
    "- It took **53 seconds** to perform 5-fold cross-validation on our Random Forest model having 10 trees.\n",
    "\n",
    "- The **training time** has **reduced** significantly and the **performance** has **improved**.\n",
    "\n",
    "- The RMSE is still significantly **lower** than the Decision Tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac342a0",
   "metadata": {},
   "source": [
    "#### **Model Comparision**\n",
    "\n",
    "**Baseline Models**\n",
    "\n",
    "| Model | RMSE Score |\n",
    "| :--: | :--: |\n",
    "| **Linear Regression** | **21612.39** |\n",
    "| **Decision Tree** | **5322.68** |\n",
    "| **Random Forest** | **3997.32** |\n",
    "\n",
    "<br>\n",
    "\n",
    "**Essential Feature Models**\n",
    "\n",
    "| Model | RMSE Score |\n",
    "| :--: | :--: |\n",
    "| **Linear Regression** | **21669.89** |\n",
    "| **Decision Tree** | **4644.98** |\n",
    "| **Random Forest** | **3686.24** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb45ec0",
   "metadata": {},
   "source": [
    "<a id = Section803></a>\n",
    "### **8.3 Hyperparameter Tuning of Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'n_estimators': [60,70,80,90], 'max_depth': [5,7,9], 'max_features': ['auto', 2, 4,6,8]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_rf = RandomForestRegressor(random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a2597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=temp_rf, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5317ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search.fit(X_train_essential, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf89ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the best RMSE score found by Grid Search \n",
    "np.sqrt(-grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hyperparameter values which provide us the best RMSE score\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e021f9",
   "metadata": {},
   "source": [
    "<a id = Section804></a>\n",
    "### **8.4 Final Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01d1eb5",
   "metadata": {},
   "source": [
    "- We found out the **best hyperparameter combinations** for our Random Forest model.\n",
    "\n",
    "- Now, we will use the model with those hyperparameters as our **final model**.\n",
    "\n",
    "- Using this final model, we will make **predictions** on our test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a452afdd",
   "metadata": {},
   "source": [
    "**Creating the Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the final random forest model from the grid search's best estimator.\n",
    "final_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afead9d",
   "metadata": {},
   "source": [
    "**Fitting the Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8fdc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the final model with training set\n",
    "final_rf.fit(X_train_essential, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21cf66",
   "metadata": {},
   "source": [
    "- After fitting the final model with the training data, we are ready to make **predictions** on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a27ac",
   "metadata": {},
   "source": [
    "**Removing Non-Essential Features from the Test Set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f649c29",
   "metadata": {},
   "source": [
    "- We trained our model on only the most important features of the dataset.\n",
    "\n",
    "- So, we need to **remove** the **non-important features** from our test set as well.\n",
    "\n",
    "- If we don't remove the non-essential features our model will give an **error** while making predictions due to the **difference in shapes** of training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the test set with only the essential features\n",
    "X_test_essential = X_test[['claim_amount', 'num_policies_More than 1', 'vintage', 'qualification_High School','qualification_High School', 'type_of_policy_Platinum', 'gender_Male', 'income_5L-10L','type_of_policy_Silver', 'income_More than 10L','claim_per_year' ]]\n",
    "X_test_essential.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3b305d",
   "metadata": {},
   "source": [
    "**Making Predictions**\n",
    "\n",
    "- Now, we will make **predictions** on both our training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc5540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the train set\n",
    "y_train_pred = final_rf.predict(X_train_essential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05963f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test set\n",
    "y_test_pred = final_rf.predict(X_test_essential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Actual Test Set Values': y_test[0:5].values, 'Predicted Test Set Values': y_test_pred[0:5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea16fd21",
   "metadata": {},
   "source": [
    "**Calculating the RMSE Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7409dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating RMSE on Train & Test Data\n",
    "print('RMSE for Train Set:', np.round(np.sqrt(mean_squared_error(y_train, y_train_pred)), decimals=2))\n",
    "print('RMSE for Test Set:', np.round(np.sqrt(mean_squared_error(y_test, y_test_pred)), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc065d2d",
   "metadata": {},
   "source": [
    "**Calculating R-Squared Value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b73a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating R-Squared on Train & Test Data\n",
    "print('R-Squared for Train Set:', np.round(r2_score(y_train, y_train_pred), decimals=2))\n",
    "print('R-Squared for Test Set:', np.round(r2_score(y_test, y_test_pred), decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a helper function to plot the actual and predicted values for train and test sets.\n",
    "def plot_score(y_train, y_train_pred, y_test, y_test_pred):\n",
    "  '''\n",
    "  Plot acutal and predicted values for train & test data\n",
    "  y_train: actual y_train values\n",
    "  y_train_pred: predicted values of y_train\n",
    "  y_test: actual y_test values\n",
    "  y_test_pred: predicted values of y_test\n",
    "  '''\n",
    "  plt.figure(figsize=[16, 6])\n",
    "  plt.subplot(1, 2, 1)\n",
    "  sns.regplot(x=y_train, y=y_train_pred, color='red')\n",
    "  plt.xlabel('Actual', size=14)\n",
    "  plt.ylabel('Predicted', size=14)\n",
    "  plt.title('For Train Data', size=16)\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  sns.regplot(x=y_test, y=y_test_pred, color='green')\n",
    "  plt.xlabel('Actual', size=14)\n",
    "  plt.ylabel('Predicted', size=14)\n",
    "  plt.title('For Test Data', size=16)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1376c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Actual vs Predicted Values\n",
    "# This will take some time\n",
    "plot_score(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541191b9",
   "metadata": {},
   "source": [
    "<a id = Section9></a>\n",
    "## **9. Conclusion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c81ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(\"test_koRSKBP.csv\")\n",
    "y_test['claim_per_year'] = creat(y_test)\n",
    "y_test = pd.get_dummies(y_test, drop_first=True)\n",
    "y_test = y_test.drop(['id'], axis=1)\n",
    "sc = s.transform(y_test[['claim_amount','claim_per_year']])\n",
    "sc = pd.DataFrame(sc ,columns=['claim_amount','claim_per_year'])\n",
    "X =X.drop(labels=['claim_amount','claim_per_year'], axis=1)\n",
    "X = pd.concat(objs=[X,sc], axis=1 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6027ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = final_rf.predict(y_test[['claim_amount', 'num_policies_More than 1', 'vintage', 'qualification_High School','qualification_High School', \n",
    "                                       'type_of_policy_Platinum', 'gender_Male', 'income_5L-10L','type_of_policy_Silver',\n",
    "                                       'income_More than 10L','claim_per_year'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d49860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
